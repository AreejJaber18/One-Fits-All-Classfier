{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreTrained_ME_BioClinical.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNR0+AmAA7UB6Ys3t8Cgisz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7yZRhX2wiR3"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSmG1NVZOkU"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR1dyQeqaPYk"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqmgUY0aaZAo"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "132_jHmsahio"
      },
      "source": [
        "!cat /proc/meminfo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-RKGi0zsaFY"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(torch.cuda.device_count())\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcA6rcFuxBWZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "#import pytorch_lightning as pl\n",
        "#from pytorch_lightning.metrics.functional.classification import auroc\n",
        "#from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJEqCacvWDZD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "187nr9hFVai1"
      },
      "source": [
        "txt_path='/content/drive/My Drive/Colab Notebooks/AnonymizedClinicalAbbreviationsAndAcronymsDataSet.txt'\n",
        "data_pd=pd.read_csv( txt_path, sep=\"|\", header=None,encoding='cp1252',)\n",
        "data_pd = data_pd.rename(columns = { 0: 'Abbreviation', 1 : 'Expansion', 2 :'ABB_frm' , 3 : \"start_pos\", 4: \"end_pos\", 5 : \"info\", 6: \"context\"}, inplace = False)\n",
        "print(data_pd.shape)\n",
        "#data_pd.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO_uIQaKQRza"
      },
      "source": [
        "data_pd=data_pd[data_pd['Abbreviation'] == 'AB']\n",
        "print(data_pd.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdEq_v8bu3sH"
      },
      "source": [
        "#check number of expansion in the dataset before filtering\n",
        "print(len(data_pd[\"Expansion\"].unique()))\n",
        "\n",
        "#filtering dataset \n",
        "data_pd.drop(data_pd[data_pd['Expansion'] == \"UNSURED SENSE\"].index, inplace = True)\n",
        "data_pd.drop(data_pd[data_pd['Expansion'] == \"GENERAL ENGLISH\"].index, inplace = True)\n",
        "data_pd.drop(data_pd[data_pd['Expansion'] == \"NAME\"].index, inplace = True)\n",
        "\n",
        "# check dataset size after filtering\n",
        "print(data_pd.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkgY1gH7m1HL"
      },
      "source": [
        "# fuction to assign numerical value to the expansion\n",
        "def func(unique_expansion, ex):\n",
        "  ex= str(ex)\n",
        "  for i in unique_expansion.items():\n",
        "    if i[0] == ex:\n",
        "      return i[1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4zpSvj5kTWi"
      },
      "source": [
        "Expansion_unique = data_pd[\"Expansion\"].unique()\n",
        "context = data_pd[\"context\"].values\n",
        "\n",
        "num= np.arange(0, 348, 1).tolist()\n",
        "unique_expansion = dict(zip(Expansion_unique,num))\n",
        "\n",
        "all_label = []\n",
        "\n",
        "for index, row in data_pd.iterrows():\n",
        "  for i in unique_expansion.items():\n",
        "    if i[0] == row[1]:\n",
        "      all_label. append(i[1]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_UQ9okqd1Zq"
      },
      "source": [
        "word2index_dict = {word: i for (i, word) in enumerate(Expansion_unique)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DpDwPzR6S8q"
      },
      "source": [
        "\n",
        "label_df = pd.DataFrame(list(word2index_dict.items()),columns = ['expansion','label'])\n",
        "label_df.to_csv('label_expansion.tsv', sep = '|')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSif6ujY2g7d"
      },
      "source": [
        "# function to clean the text\n",
        "import re\n",
        "import string\n",
        "def cleaning(context_):\n",
        "  x=re.sub(\"_%#\\S+\", \"\", context_)\n",
        "  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
        "  x = re.sub(r'\\w*\\d+\\w*','', x)\n",
        "  x = re.sub('\\s{2,}', \" \", x)\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9oRiBmj1A3I"
      },
      "source": [
        "#filtered dataset after cleaning text and labeled expansion\n",
        "filtered_data = pd.DataFrame()\n",
        "filtered_data['content'] = data_pd['context']#.apply(cleaning)\n",
        "filtered_data['expansion'] = data_pd['Expansion']\n",
        "filtered_data['label'] = all_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLwRzNLQkV2N"
      },
      "source": [
        "filtered_data['label'][5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhy95DydAGgv"
      },
      "source": [
        "#override dataset\n",
        "class DisambiguateDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data: pd.DataFrame, tokenizer, max_token_len ):\n",
        "\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_token_len = max_token_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "\n",
        "    data_row = self.data.iloc[index]\n",
        "    context =data_row['content']\n",
        "    expansion = data_row['expansion']\n",
        "    label_ = data_row['label']\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        expansion, context, \n",
        "        #text_pair = expansion,\n",
        "        add_special_tokens = True,\n",
        "        max_length = 128,\n",
        "        return_token_type_ids = True,\n",
        "        padding = \"max_length\",\n",
        "        truncation =True,\n",
        "        return_attention_mask = True,\n",
        "        return_tensors = \"pt\"\n",
        "     \n",
        "    )\n",
        "    return dict(\n",
        "      input_ids = encoding[\"input_ids\"].flatten(),\n",
        "      attention_mask = encoding[\"attention_mask\"].flatten(),\n",
        "      token_type_ids = encoding[\"token_type_ids\"].flatten(),\n",
        "      label_ = torch.tensor(label_,dtype = torch.long)\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TctrJoJPlOm",
        "outputId": "0dedc7d6-e543-4c6e-b864-99bce94d4216"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 2\n",
        "\n",
        "# divide the data set to training and validation dataset and check the ne w size for both\n",
        "train_df, test_df = train_test_split(filtered_data,test_size=0.2, random_state = RANDOM_SEED)\n",
        "val_df, test_df = train_test_split(test_df,test_size=0.5, random_state = RANDOM_SEED)\n",
        "train_df.shape, val_df.shape, test_df.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((29560, 3), (3695, 3), (3695, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWvkbjiIR4ct",
        "outputId": "b6d0f1ea-99ce-4c88-dd97-9f8ced850198"
      },
      "source": [
        "test_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['content', 'expansion', 'label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "Vd2KPmDWMpGW",
        "outputId": "665d834a-9ea6-4b63-da0c-4ccbf5b8ddc7"
      },
      "source": [
        "filtered_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBJpabNcmEBL"
      },
      "source": [
        "# Download Bio_clinicalBERT \n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, BertForNextSentencePrediction, BertTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
        "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFHS9KiIrGzC"
      },
      "source": [
        "#Download ms_bert\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "model_name = \"NLP4H/ms_bert\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvBJ74U1gyzf"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZrSM_LtTDpz"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = DisambiguateDataset(df, tokenizer, max_len)\n",
        "\n",
        "  return torch.utils.data.DataLoader(ds, batch_size = batch_size, shuffle = True )  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwNKKzq1T-zI"
      },
      "source": [
        "train_data_loader = create_data_loader(train_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(val_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNZLYjr4bWuP"
      },
      "source": [
        "data = next(iter(val_data_loader))\n",
        "data.keys()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkvzAW0Zm-ut"
      },
      "source": [
        "out = clinic_model(data['input_ids'].to(device), data['attention_mask'].to(device), data['token_type_ids'].to(device))\n",
        "out[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbatMHjvRLRK"
      },
      "source": [
        "correct_predictions = 0\n",
        "_, preds = torch.max(out, dim=1)\n",
        "preds[0] , data['label_']\n",
        "loss = loss_fn(out,data['label_'].to(device))\n",
        "loss\n",
        "#correct_predictions += torch.sum(preds == data['label_'].to(device))\n",
        "#correct_predictions\n",
        "#preds[0], data['label_'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMp2EGu1e1ll"
      },
      "source": [
        "out['pooler_output'].shape , out['hidden_states'][0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70FgbcJqhQJ3"
      },
      "source": [
        "class DisambiguateClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(DisambiguateClassifier, self).__init__()\n",
        "    self.model = model\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "     nn.Linear(self.model.config.hidden_size, 512),\n",
        "     nn.ReLU(),\n",
        "    nn.Linear(512, 348),\n",
        "    )\n",
        "    \n",
        "  \n",
        "  \n",
        "  def forward(self, input_ids, token_type_ids, attention_mask ):\n",
        "    output = self.model(\n",
        "        input_ids,\n",
        "       token_type_ids, \n",
        "       attention_mask,\n",
        "      \n",
        "    \n",
        "    )\n",
        "    out = self.linear_relu_stack (output['last_hidden_state'][:,0,:])\n",
        "    return out\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtjjXn8hlyEz"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "clinic_model = DisambiguateClassifier(model)\n",
        "clinic_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4rethD4q5YC"
      },
      "source": [
        "class DisambiguateClassifier(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super(DisambiguateClassifier, self).__init__()\n",
        "    self.model = model\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(768, 512),\n",
        "        nn.Dropout(.3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 340),\n",
        "        nn.Dropout(.3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(340, 498),\n",
        "        #nn.Softmax(dim=1)\n",
        "        )\n",
        "    \n",
        "  def forward(self, input_ids, token_type_ids, attention_mask ):\n",
        "    output = self.model(\n",
        "        input_ids = input_ids,\n",
        "        token_type_ids = token_type_ids, \n",
        "        attention_mask =  attention_mask\n",
        "    )\n",
        "    out = self.linear_relu_stack(output['last_hidden_state'][:,0,:])\n",
        "    return out\n",
        "\n",
        "\n",
        "        \n",
        "       \n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99KDT7FBhhmq"
      },
      "source": [
        "optimizer = AdamW(clinic_model.parameters(), lr = 1e-5 )\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps = 0,\n",
        "    num_training_steps = total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubM8ehqLqVwP"
      },
      "source": [
        "def train_epoch(\n",
        "    model,\n",
        "    data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    n_examples\n",
        "):\n",
        " model = model.train()\n",
        "\n",
        " losses = []\n",
        " correct_predictions = 0\n",
        "\n",
        " for d in data_loader:\n",
        "   input_ids = d['input_ids'].to(device)\n",
        "   attention_mask = d['attention_mask'].to(device)\n",
        "   token_type_ids = d['token_type_ids'].to(device)\n",
        "   label = d['label_'].to(device)\n",
        "\n",
        "   outputs = model(\n",
        "       input_ids,\n",
        "       attention_mask,\n",
        "      token_type_ids,\n",
        "   )\n",
        "\n",
        "   _, preds = torch.max(outputs, dim=1)\n",
        "   loss = loss_fn(outputs,label)\n",
        "\n",
        "   correct_predictions += torch.sum(preds == label)\n",
        "   losses.append(loss.item())\n",
        "\n",
        "   loss.backward()\n",
        "   nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "   optimizer.step()\n",
        "   scheduler.step()\n",
        "   optimizer.zero_grad()\n",
        "\n",
        " return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaoodV_Ws4UA"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  prediction = []\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for d in data_loader:\n",
        "\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      token_type_ids = d['token_type_ids'].to(device)\n",
        "      label = d['label_'].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "      input_ids,\n",
        "      attention_mask,\n",
        "      token_type_ids,\n",
        "      \n",
        "   )\n",
        "\n",
        "      \n",
        "      _,preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, label)\n",
        "      for p,x, ii in zip(preds,label,input_ids):\n",
        "        if p.item() != x.item():\n",
        "          print(p.item(),\",\", x.item(),\",\",tokenizer.decode(ii,skip_special_tokens= True))\n",
        "       \n",
        "      correct_predictions += torch.sum(preds == label)\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      #prediction = torch.stack(prediction).cpu()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hh5mCCztUrk"
      },
      "source": [
        "#EPOCHS = 1\n",
        "from collections import defaultdict\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "history = defaultdict(list)\n",
        "\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    clinic_model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(train_df)\n",
        " )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "\n",
        "    clinic_model,\n",
        "\n",
        "    val_data_loader,\n",
        "\n",
        "    loss_fn,\n",
        "\n",
        "    device,\n",
        "\n",
        "    len(val_df)\n",
        "\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "\n",
        "  history['train_loss'].append(train_loss)\n",
        "\n",
        "  history['val_acc'].append(val_acc)\n",
        "\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSGVikvND7b4"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlrBXSmGEGkM"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "\n",
        "  clinic_model,\n",
        "\n",
        "  test_data_loader,\n",
        "\n",
        "  loss_fn,\n",
        "\n",
        "  device,\n",
        "\n",
        "  len(test_df)\n",
        "\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_EDrZ4bES9R"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "\n",
        "  model = model.eval()\n",
        "\n",
        "  text = []\n",
        "\n",
        "  predictions = []\n",
        "\n",
        "  real_values = []\n",
        "  texts = []\n",
        "  \n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for d in data_loader:\n",
        "\n",
        "\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
        "\n",
        "\n",
        "      targets = d[\"label_\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "\n",
        "        input_ids=input_ids,\n",
        "\n",
        "        attention_mask=attention_mask,\n",
        "        token_type_ids = token_type_ids,\n",
        "\n",
        "      )\n",
        "\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      #for xx in input_ids:\n",
        "        #text.extend(tokenizer.decode(xx,skip_special_tokens=True))\n",
        "\n",
        "      predictions.extend(preds)\n",
        "\n",
        "      real_values.extend(d['label_'])\n",
        "  texts.extend(text)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "\n",
        "  #texts = torch.stack(texts).cpu()\n",
        "\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "\n",
        "  return  predictions, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0EulXWVEcjv"
      },
      "source": [
        "y_pred, y_test = get_predictions(clinic_model,test_data_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS2xYcYTmaim"
      },
      "source": [
        "text = []\n",
        "for d in test_data_loader:\n",
        "  for dd in d['input_ids']:\n",
        "    text.append(tokenizer.decode(dd, skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHh__MSs7gkP",
        "outputId": "16930db9-1862-415b-d013-2180f4d60d9a"
      },
      "source": [
        "prediction = []\n",
        "for i in y_pred:\n",
        "  prediction.append(i.item())\n",
        "len(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3695"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slf3vZWn758X",
        "outputId": "b4318c80-dc5a-457d-b39b-31b4677a8616"
      },
      "source": [
        "real = []\n",
        "for i in y_test:\n",
        "  real.append(i.item())\n",
        "len(real)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3695"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbWHI9Yg8E1d"
      },
      "source": [
        "test_result_df = pd.DataFrame()\n",
        "test_result_df['text'] = text\n",
        "test_result_df['prediction'] = prediction\n",
        "test_result_df['real'] = real\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCwU7LgO9snW"
      },
      "source": [
        "test_result_df.to_csv('test_result_prediction.tsv', sep = '|')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yVciTO1EdZC"
      },
      "source": [
        "#print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "#print(y_pred)\n",
        "for i in y_pred:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn76A4ho2TvG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fo1Ng7E2VHQ",
        "outputId": "447e0436-d204-4931-d6de-0372a1434e28"
      },
      "source": [
        "d = next(iter(test_data_loader))\n",
        "print(d.keys())\n",
        "test_df['label']\n",
        "all_input = []\n",
        "for i in test_data_loader:\n",
        "  input = i['input_ids']\n",
        "  all_input.extend(input)\n",
        "\n",
        "all_input=torch.stack(all_input).cpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQdtQjsKQZhU"
      },
      "source": [
        "all_input=torch.stack(all_input).cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KB9iCiHQb8A"
      },
      "source": [
        "predicted_label = [73,298,34,107,148,325,201,79,285,63,68,93,233,143,281,85,45,34,117,281,155,298,89,0,344,149]\n",
        "pred_expansion = []\n",
        "for i in predicted_label:\n",
        "  for j, row in label_df.iterrows():\n",
        "    if row[1] == i:\n",
        "      pred_expansion. append(row[0])\n",
        "pred_expansion"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}